q()
install.packages(c("swirl", "httr", "RCurl", "yaml", "bitops", "mime", "testthat", "crayon"))
install.packages(c("jsonlite", "memoise", "biganalytics"))
install.packages("bigmemory")
install.packages("bigmemory.sri")
install.packages(c("manipulate", "geoR"))
install.packages("ggplot2")
install.packages("dplyr")
install.packages("biganalytics")
install.packages("bigmemory")
install.packages(c("knitr", "kfigr", "stringr", "dplyr"))
install.packages("biganalytics")
?gbm
??gbm
?rpart
find.package("devtools")
install.packages("devtools")
library(devtools)
find_rtools()
install.packages("KernSmooth")
load(KernSmooth)
library(KernSmooth)
install.packages(xlsx)
install.package(xlsx)
install.packages(xlsx)
install.packages("xlsx")
library(XML)
fileUrl <- "http://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
names(rootNode)
names(rootNode)
rootNode[[1]]
rootNode[[4]]
rootNode[[1]]
rootNode[[1]][[1]]
rootNode[[1]][[3]]
rootNode[[1]][[9]]
rootNode[[1]][[1]]
xmlSApply(rootNode,xmlValue)
xmlSApply(rootNode,"//name",xmlValue)
xpathSApply(rootNode,"//name",xmlValue)
?XML
??XML
install.packages("jsonlite")
install.packages("RMySQL")
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
installed.packages("biocLite")
library("biocLite")
biocLite("rhdf5")
library(rhdf5)
library(httr)
installed.packages(lubridate)
install.packages(lubridate)
install.packages("lubridate")
setwd("C:/Users/eayres/Documents/GitHub/datasciencecoursera/Data Science Specialization/03 Getting+Cleaning Data/Quizes/Quiz4")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile="fsspid.csv", mode="w")
dateDownloaded <- date()
print(dateDownloaded)
library(data.table)
data <- fread(input="fsspid.csv", sep=",")
splitnames = strsplit(names(data),"wgtp")
strsplit(names(data),"wgtp")
View(data)
123element <- function(x){x[123]}
element <- function(x){x[123]}
sapply(splitnames,element)
colname <- names(data)
colname <- names(data)
splitcolname <- strsplit(colname, "wgtp")
splitcolname[[123]]
setwd("C:/Users/eayres/Documents/GitHub/datasciencecoursera/Data Science Specialization/03 Getting+Cleaning Data/Quizes/Quiz4")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile="gdp.csv", mode="w")
dateDownloaded <- date()
print(dateDownloaded)
library(data.table)
data <- fread(input="gdp.csv", sep=",")
download.file(fileUrl, destfile="gdp.csv", mode="wb")
dateDownloaded <- date()
print(dateDownloaded)
library(data.table)
data <- fread(input="gdp.csv", sep=",")
View(data)
data$V5
data2 <- data[1:194]
View(data2)
data2 <- data[5:194]
data3 <- gsub(",", "", data2)
data3 <- gsub(",", "", data2$V5)
data3
as.numeric(data3)
average(as.numeric(data3))
summary(as.numeric(data3))
sum(as.numeric(data3))
nrows(data3)
nrows(as.numeric(data3)
)
nrows(as.numeric(data3))
sum(as.numeric(data3))/190
## remove row that don't include gdp data
data2 <- data[5:194]
## remove commas from gdp and replace with nothing
data3 <- gsub(",", "", data2$V5)
## convert gdp to numeric values, sum them, then divide by number of rows (i.e. 190)
sum(as.numeric(data3))/190
View(data2)
colname(data2$V4) <- c("countryNames")
colnames(data2$V4) <- c("countryNames")
names(data2)
colnames(data2) <- c("V1",  "Gross domestic product 2012", "V3",  "countryNames", "V5", "V6", "V7", "V8","V9","V10")
grep("*United",countryNames)
countryNames <- data2$countryNames
grep("*United",countryNames)
grep("United$",countryNames)
grep("^United",countryNames)
grep("*United",countryNames)
data2 <- data[5:194]
countryNames <- data2$v4
countryNames
countryNames <- data2[,4]
countryNames
data2$v4
countryNames <- data2$V4
countryNames
grep("*United",countryNames, values=TRUE)
grep("*United",countryNames)
grep("United$",countryNames)
grep("^United",countryNames)
grep("*United",countryNames)
setwd("C:/Users/eayres/Documents/GitHub/datasciencecoursera/Data Science Specialization/03 Getting+Cleaning Data/Quizes/Quiz4")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile="gdp1.csv", mode="wb")
dateDownloaded <- date()
print(dateDownloaded)
fileUrl2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl2, destfile="edu.csv", mode="wb")
dateDownloaded <- date()
print(dateDownloaded)
library(data.table)
data <- fread(input="gdp1.csv", sep=",")
data <- fread(input="edu.csv", sep=",")
edu <- fread(input="edu.csv", sep=",")
gdp <- fread(input="gdp1.csv", sep=",")
View(edu)
View(gdp)
gdp2 <- gdp[5:194]
head(gdp2)
head(edu)
mergedData <- merge(gdp2,edu,by.x = "V1", by.y = "CountryCode", all=FALSE)
View(mergedData)
mergedData$`Special Notes`
FYinfo <- mergedData$`Special Notes`
grep("fiscal year|Fiscal year", FYinfo)
FYinfo2 <- grepl("fiscal year|Fiscal year", FYinfo)
FYinfo2 <- FYinfo[grepl("fiscal year|Fiscal year", FYinfo),]
FYinfo[grepl("fiscal year|Fiscal year", FYinfo),]
FYinfo2 <- FYinfo[grepl("Fiscal year", FYinfo),]
grep("Fiscal year", FYinfo,value=TRUE)
grep("Fiscal year|fiscal year", FYinfo,value=TRUE)
grep("Fiscal year", FYinfo,value=TRUE)
grep("Fiscal year end: ", FYinfo,value=TRUE)
grep("Fiscal year end: June", FYinfo,value=TRUE)
library(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
View(amzn)
rownames(amzn)
sampleTimes
grep("^2012", sampleTimes)
Times2012 <- grep("^2012", sampleTimes)
Times2012 <- grep("^2012", sampleTimes, values=TRUE)
grep("^2012", sampleTimes, values=TRUE)
Times2012 <- grep("^2012", sampleTimes, value = TRUE)
Times2012 <- grep("^2012", sampleTimes, value = TRUE)
Times2012
class(Times2012)
format(Times2012,%Y, %m, %d)
as.Date(Times2012, %Y, %m, %d)
as.Date(Times2012, %Y-%m-%d)
as.Date(Times2012, %Y %m %d)
format(Times2012,%Y %m %d)
x = as.Date(Times2012, %Y %m %d)
x = as.Date(Times2012, "%Y %m %d")
x
x = as.Date(Times2012, "%Y-%m-%d")
x
head(x)
weekdays(x)
y <- weekdays(x)
grep("Monday", y)
z <- grep("Monday", y)
